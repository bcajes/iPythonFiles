{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mastering Open CV with Practical Computer Vision Projects\n",
    "1. Cartoonifer and Skin Changer for Android\n",
    "    - accessing the webcam\n",
    "    - main camera processing loop for a desktop app\n",
    "    - generating a black-and-white sketch\n",
    "    - generating a color painting and a cartoon\n",
    "    - generating an \"evil\" mode using edge filters\n",
    "    - generating an \"alien\" mode using skin detection\n",
    "    - Porting from desktop to Android\n",
    "2. Marker-based Augmented Reality on iPhone or iPad\n",
    "    - creating an iOS project that uses OpenCV\n",
    "    - Application architecture\n",
    "    - marker detection\n",
    "    - placing a marker in 3D\n",
    "    - rendering the 3D virtual object\n",
    "3. Marker-less augmented reality\n",
    "    - marker-based versus marker-less AR\n",
    "    - using feature descriptors to find an arbitrary image on video\n",
    "    - Pattern pose estimation\n",
    "    - application infrastructure\n",
    "4. Exploring Structure from Motion using OpenCV\n",
    "    - structure from motion concepts\n",
    "    - estimating the camera motion from a pair of images\n",
    "    - reconstructing the scene\n",
    "    - reconstruction from many view\n",
    "    - refinement of the reconstruction\n",
    "    - visualizing 3D point clouds with PCL\n",
    "5. Number Plate recognition using SVM and neural networks\n",
    "    - ANPR algortihm\n",
    "    - plate detection\n",
    "    - plate recognition\n",
    "6. Non-rigid Face tracking\n",
    "    - utilities\n",
    "    - geometrical constraints\n",
    "    - facial feature detectors\n",
    "    - face detection and initialization\n",
    "    - face tracking\n",
    "7. 3D Head Pose Estimation using AAM and POSIT\n",
    "    - active appearance models overview\n",
    "    - active shape models\n",
    "    - model instantiation - playing with the active appearance model\n",
    "    - AAM search and fitting\n",
    "    - POSIT\n",
    "8. Face recognition using Eigenfaces or Fisherfaces\n",
    "    - introduction to face recognition and face detection\n",
    "        - face detection\n",
    "        - face preprocessing\n",
    "        - collecting faces and learning from them\n",
    "        - face recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Image Statistics - A Probabilistic Approach to Early Computational Vision\n",
    "1. Introduction\n",
    "    - what this book is all about\n",
    "    - what is vision?\n",
    "    - the magic of your visual system\n",
    "    - importance of prior information\n",
    "        - ecological adaptation provides prior information\n",
    "        - generative models and latent quantities\n",
    "        - projection onto the retina loses information\n",
    "        - bayesian inference and priors\n",
    "    - natural images\n",
    "        - the image space\n",
    "        - definition of natural images\n",
    "    - redundancy and information\n",
    "        - information theory and image coding\n",
    "        - redundancy reduction and neural coding\n",
    "    - statistical modeling of the visual system\n",
    "        - connecting information theory and bayesian inference\n",
    "        - normative vs. descriptive modeling of visual system\n",
    "        - toward predictive theoretical neuroscience\n",
    "    - Features and statistical models of natural images\n",
    "        - image representations and features\n",
    "        - statistics of features\n",
    "        - from features to statistical models\n",
    "    - the statistical-ecological approach recapitulated\n",
    "2. Background\n",
    "    1. Linear Filters and Frequency Analysis\n",
    "        - linear filtering\n",
    "            - definition\n",
    "            - impulse response and convolution\n",
    "        - frequency-based representation\n",
    "            - motivation\n",
    "            - representation in one and two dimensions\n",
    "            - frequency-based representation and linear filtering\n",
    "            - computation and mathematical details\n",
    "        - representation using linear bias\n",
    "            - basic idea\n",
    "            - frequency-based representation as a basis\n",
    "        - space-frequency analysis\n",
    "            - space-frequency analysis and gabor filters\n",
    "            - spatial localization vs. spectral accuracy\n",
    "    2. Outline of the Visual System\n",
    "        - neurons and firing rates\n",
    "        - from the eye to the cortex\n",
    "        - linear models of visual neurons\n",
    "            - responses to visual stimulation\n",
    "            - simple cells and linear models\n",
    "            - gabor models and selectives of simple cells\n",
    "            - frequency channels\n",
    "        - non-linear models of visual neurons\n",
    "            - non-linearities in simple cell responses\n",
    "            - complex cells and energy models\n",
    "        - interactions between visual neurons\n",
    "        - topogrpahic organization\n",
    "        - processing after the primary visual cortex\n",
    "    3. Multivariate Probability and Statistics\n",
    "        - natural image patches as random vectors\n",
    "        - multivariate probability distributions\n",
    "            - notation and motivation\n",
    "            - probability density function\n",
    "        - marginal and joint probabilities\n",
    "        - conditional probabilities\n",
    "        - independence\n",
    "        - expectation and covariance\n",
    "            - expectation \n",
    "            - variance and covariance in one dimension\n",
    "            - covariance matrix\n",
    "            - independence and covariances\n",
    "        - Bayesian Inference\n",
    "            - motivating examples\n",
    "            - Bayes' Rule\n",
    "            - Non-informative Priors\n",
    "            - Bayesian Inference as an Incremental Learning Process\n",
    "        - Parameter Estimation and Likelihood\n",
    "            - Models, Estimation and Samples\n",
    "            - Maximum Likelihood and Maximum a Posteriori\n",
    "            - Prior and Large Samples\n",
    "3. Statistics of Linear Features\n",
    "    1. Principal Components and Whitening\n",
    "        - DC Component or Mean Grey-Scale Value\n",
    "        - Principal Component Analysis\n",
    "            - A basic dependency of pixels in natural images\n",
    "            - learning on feature by maximization of variance\n",
    "            - learning many features by PCA\n",
    "            - computational implementation of PCA\n",
    "            - the implications of translation-invariance\n",
    "        - PCA as a preprocessing tool\n",
    "            - dimension reduction by PCA\n",
    "            - whitening by PCA\n",
    "            - anti-aliasing by PCA\n",
    "         - Canonical Preprocessing used in this book\n",
    "         - Gaussianity as the basis for PCA\n",
    "             - the probability model related to PCA\n",
    "             - PCA as a generative model\n",
    "             - image synthesis results\n",
    "         - Power Spectrum of Natural Images\n",
    "             - the 1/*f* Fourier amplitude or 1/$f^2$ Power Spectrum\n",
    "             - connection between power spectrum and covariances\n",
    "             - relative importance of amplitude and phase\n",
    "         - anisotropy in natural images\n",
    "         - mathematics of principal component analysis\n",
    "             - eigenvalue decomposition of the covariance matrix\n",
    "             - eigenvectors and translation-invariance\n",
    "         - decorrelation models of retina and LGN\n",
    "             - whitening and redundancy reduction\n",
    "             - patch-based decorrelation\n",
    "             - filter-based decorrelation\n",
    "    2. Sparse Coding and Simple Cells\n",
    "        - definition of sparseness\n",
    "        - learning one feature by maximization of sparseness\n",
    "            - measuring sparseness: general framework\n",
    "            - measuring sparseness using kurtosis\n",
    "            - measuring sparseness using convex functions of square\n",
    "            - the case of canonically preprocessed data\n",
    "            - one feature learned from natural image\n",
    "        - learning many features by maximization of sparseness\n",
    "            - deflationary decorrelation\n",
    "            - symmetric decorrelation\n",
    "            - sparseness of feature vs. sparseness of representation\n",
    "        - sparse coding features for natural images\n",
    "            - full set of features\n",
    "            - analysis of tuning properties\n",
    "        - how is sparseness useful?\n",
    "            - Bayesian modeling\n",
    "            - neural modeling \n",
    "            - metabolic economy\n",
    "    3. Independent Component Analysis\n",
    "        - limitations of the sparse coding approach\n",
    "        - definition of ICA\n",
    "            - independence\n",
    "            - generative model\n",
    "            - model for preprocessed data\n",
    "        - insufficiency of second-order information\n",
    "            - why whitening does not find independent components\n",
    "            - why components have to be non-gaussian\n",
    "        - the probability density defined by ICA\n",
    "        - maximum likelihood estimation in ICA\n",
    "        - results on Natural images\n",
    "            - estimation of features\n",
    "            - image synthesis using ICA\n",
    "        - Connection to maximization of sparseness\n",
    "            - likelihood as a measure of sparseness\n",
    "            - optimal sparseness measures\n",
    "        - why are independent components sparse?\n",
    "            - different forms of non-gaussianity\n",
    "            - non-gaussianity in natural images\n",
    "            - why is sparseness dominant?\n",
    "        - general ICA as maximization of non-gaussianity\n",
    "            - central limit theorem\n",
    "            - \"non-gaussian is independent\"\n",
    "            - sparse coding as a special case of ICA\n",
    "        - receptive fields vs. feature vectors\n",
    "        - problem of inverision of preprocessing\n",
    "        - frequency channels and ICA\n",
    "    4. Information-Theoretic Interpretations\n",
    "        - basic motivation for information theory\n",
    "            - compression\n",
    "            - transmission\n",
    "        - entropy as a measure of uncertainty\n",
    "            - definition of entropy\n",
    "            - entropy as minimum coding length\n",
    "            - redundancy\n",
    "            - differential entropy\n",
    "            - maximum entropy\n",
    "        - mutual information\n",
    "        - minimum entropy coding of natural images\n",
    "            - image compression and sparse coding\n",
    "            - mutual information and sparse coding\n",
    "            - minimum entropy coding in the cortex\n",
    "        - information transmission in the nervous system\n",
    "            - definition of information flow and Infomax\n",
    "            - Basic Infomax with Linear neurons\n",
    "            - Infomax with Non-linear Neurons\n",
    "            - Infomax with Non-constant Noise variance\n",
    "        - Caveats in Application of Information theory\n",
    "4. Nonlinear Features and Dependency of Linear Features\n",
    "    1. Energy Correlation of Linear Features and Normalization\n",
    "        - why estimated independent components are not independent\n",
    "            - estimates vs. theoretical components\n",
    "            - counting the number of free parameters\n",
    "        - correlations of squares of components in natural images\n",
    "        - modeling using a variance variable\n",
    "        - normalization of variance and contrast gain control\n",
    "        - physical and neurophysiological interpretations\n",
    "            - canceling the effect of changing lighting conditions\n",
    "            - uniform surfaces\n",
    "            - saturation of cell responses\n",
    "        - effect of normalization on ICA\n",
    "    2. Energy Detectors and Complex Cells\n",
    "        - subspace model of invariant features\n",
    "            - why linear filters are insufficient\n",
    "            - subspaces or groups of linear features\n",
    "            - energy model of feature detection\n",
    "        - maximizing sparseness in the energy model\n",
    "            - definition of sparseness of output\n",
    "            - one feature learned from natural images\n",
    "        - model of independent subspace analysis\n",
    "        - dependency as energy correlation\n",
    "            - why energy correlations are related to sparseness\n",
    "            - spherical symmetry and changing variance\n",
    "            - correlation of squares and convexity of non-linearity\n",
    "        - connection to contrast gain control\n",
    "        - ISA as a non-linear version of ICA\n",
    "        - results on natural images\n",
    "            - emergence of invariance to phase\n",
    "            - the importance of being invariant\n",
    "            - grouping of dependencies\n",
    "            - superiority of the model over ICA\n",
    "        - Analysis of convexity and energy correlations\n",
    "            - variance variable model gives convex *h*\n",
    "            - Convex *h* typically implies positive energy correlations\n",
    "    3. Energy Correlations and Topographic Organization\n",
    "        - topography in the cortex\n",
    "        - modeling topography by statistical dependence\n",
    "            - topographic grid\n",
    "            - defining topography by statistical dependencies\n",
    "        - definition of topographic ICA\n",
    "        - connection to independent subspaces and invariant features\n",
    "        - utility of topography\n",
    "        - estimation of topographic ICA\n",
    "        - topographic ICA of natural images\n",
    "            - emergence of V1-like topography\n",
    "            - comparison with other models\n",
    "        - learning both layers in a two-layer model\n",
    "            - generative vs. energy-based approach\n",
    "            - definition of the generative model\n",
    "            - basic properties of the generative model\n",
    "            - estimation of the generative model\n",
    "            - energy-based two-layer models\n",
    "    4. Dependencies of Energy Detectors: Beyond V1\n",
    "        - predictive modeling of extrastriate cortex\n",
    "        - simulation of V1 by a fixed two-layer model\n",
    "        - learning the third layer by another ICA model\n",
    "        - methods for analyzing higher-order components\n",
    "        - results on natural images\n",
    "            - emergence of collinear contour units\n",
    "            - emergence of pooling over frequencies\n",
    "        - discussion of results\n",
    "            - why coding of contours?\n",
    "            - frequency channels and edges\n",
    "            - toward predictive modeling\n",
    "    5. Overcomplete and Non-negative models\n",
    "        - Overcomplete Bases\n",
    "            - motivation\n",
    "            - definition of generative model\n",
    "            - nonlinear computation of the basis coefficients\n",
    "            - estimation of the basis\n",
    "            - approach using energy-based models\n",
    "            - results on natural images\n",
    "            - markov random field models\n",
    "        - non-negative models\n",
    "            - motivation\n",
    "            - definition\n",
    "            - adding sparseness constraints\n",
    "    6. Lateral interactions and Feedback\n",
    "        - feedback as Bayesian inference\n",
    "            - example: contour integrator units\n",
    "            - thresholding (shrinkage) of a sparse code\n",
    "            - categorization and top-down feedback\n",
    "        - overcomplete basis and end-stopping\n",
    "        - predictive coding\n",
    "5. Time, Color, and Stereo\n",
    "    1. Color and stereo images\n",
    "        - color image experiments\n",
    "            - choice of data\n",
    "            - preprocessing and PCA\n",
    "            - ICA Results and discussion\n",
    "        - stereo image experiments\n",
    "            - choice of data\n",
    "            - preprocessing and PCA\n",
    "            - ICA results and discussion\n",
    "        - further references\n",
    "            - color and stereo images\n",
    "            - other modalities, including audition\n",
    "    2. Temporal sequences of natural images\n",
    "        - natural image sequences and spatiotemporal filtering\n",
    "        - temporal and spatiotemporal receptive fields\n",
    "        - second-order statistics\n",
    "            - average spatiotemporal power spectrum\n",
    "            - the temporally decorrelating filter\n",
    "        - sparse coding and ICA of natural image sequences\n",
    "        - temporal coherence in spatial features\n",
    "            - temporal coherence and invariant representation\n",
    "            - quantifying temporal coherence\n",
    "            - interpretation as generative model\n",
    "            - experiments on natural image sequences\n",
    "            - why gabor-like features maximize temporal coherence\n",
    "            - control experiments\n",
    "        - spatiotemporal energy correlations in energy features\n",
    "            - definition of the model\n",
    "            - estimation of the model\n",
    "            - experiments on natural images\n",
    "            - intuitive explanation of results\n",
    "        - unifying model of spatiotemporal dependencies\n",
    "        - features with minimal average temporal change\n",
    "            - slow feature analysis\n",
    "            - quadratic slow feature analysis\n",
    "            - sparse slow feature analysis\n",
    "6. Conclusion\n",
    "    1. Conclusion and Future Prospects\n",
    "        - short overview\n",
    "        - open, or Frequently asked, questions\n",
    "            - what is the real learning principle in the brain?\n",
    "            - Nature vs. Nurture\n",
    "            - how to model whole images\n",
    "            - are there clear-cut cell types?\n",
    "            - how far can we go?\n",
    "        - other mathematical models of images\n",
    "            - scaling laws\n",
    "            - wavelet theory\n",
    "            - physically inspired models\n",
    "7. Supplementary Mathematical Tools\n",
    "    1. Optimization Theory and Algorithms\n",
    "        - levels of modeling\n",
    "        - gradient method\n",
    "            - definition and meaning of gradient\n",
    "            - gradient and optimization\n",
    "            - optimization function of matrix\n",
    "            - constrained optimization\n",
    "        - global and local maxima\n",
    "        - Hebb's rule and gradient methods\n",
    "            - Hebb's rule\n",
    "            - Hebb's rule and optimization\n",
    "            - stochastic gradient methods\n",
    "            - role of the hebbian non-linearity\n",
    "            - receptive fields vs. synaptic strengths\n",
    "            - the problem of feedback\n",
    "        - optimization in topographic ICA\n",
    "        - beyond basic gradient methods\n",
    "            - newton's method\n",
    "            - conjugate gradient methods\n",
    "        - FastICA, a Fixed-Point Algorithm for ICA\n",
    "            - the FastICA Algorithm\n",
    "            - Choice of the FastICA Non-linearity\n",
    "            - Mathematics of FastICA\n",
    "    2. Crash Course in Linear Algebra\n",
    "        - vectors\n",
    "        - linear transformations\n",
    "        - matrices\n",
    "        - determinant\n",
    "        - inverse\n",
    "        - basis representations\n",
    "        - orthogonality\n",
    "        - pseudo-inverse\n",
    "    3. The Discrete Fourier Transform\n",
    "        - linear shift-invariant systems\n",
    "        - one-dimensional discrete fourier transform\n",
    "            - Euler's formula\n",
    "            - representation in complex exponentials\n",
    "            - the discrete Fourier transform and its inverse\n",
    "        - two- and three-dimensional discrete Fourier transforms\n",
    "    4. Estimation of Non-normalized statistical models\n",
    "        - Non-normalized statistical models\n",
    "        - estimation by score matching\n",
    "        - Ex.1: Multivariate Gaussian Density\n",
    "        - Ex.2: Estimation of Basic ICA Model\n",
    "        - Ex.3: Estimation of an Overcomplete ICA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Neural Networks for Pattern Recognition\n",
    "1. Statistical Pattern Recognition\n",
    "    - classification and regression\n",
    "    - pre-processing and feature extraction\n",
    "    - the curse of dimensionality\n",
    "    - polynomial curve fitting\n",
    "    - model complexity\n",
    "    - multivariate non-linear functions\n",
    "    - Bayes' theorem\n",
    "    - Decision boundaries\n",
    "    - Minimizing risk\n",
    "2. Probability Density Estimation\n",
    "    - parametric methods\n",
    "    - maximum likelihood\n",
    "    - Bayesian inference\n",
    "    - Sequential parameter estimation\n",
    "    - Non-parametric methods\n",
    "    - Mixture models\n",
    "3. Single-Layer Networks\n",
    "    - linear discriminant functions\n",
    "    - linear separability\n",
    "    - generalized linear discriminants\n",
    "    - least-squares techniques\n",
    "    - the perceptron\n",
    "    - fisher's linear discriminant\n",
    "4. The Multi-Layer Perceptron\n",
    "    - feedforward network mappings\n",
    "    - threshold units\n",
    "    - sigmoidal units\n",
    "    - weight-space symmetries\n",
    "    - higher-order networks\n",
    "    - projection pursuit regression\n",
    "    - Kolmogorov's theorem\n",
    "    - error back-propagation\n",
    "    - the Jacobian matrix\n",
    "    - the Hessian matrix\n",
    "5. Radial Basis Functions\n",
    "    - Exact interpolation\n",
    "    - Radial basis function networks\n",
    "    - network training\n",
    "    - regularization theory\n",
    "    - noisy interpolation theory\n",
    "    - relation to kernel regression\n",
    "    - radial bassi function networks for classification\n",
    "    - comparison with the multi-layer perceptron\n",
    "    - basis fuction optimization\n",
    "    - supervised training\n",
    "6. Error Functions\n",
    "    - sum-of-squares error\n",
    "    - Minkowski error\n",
    "    - Input-dependent variance\n",
    "    - modelling conditional distributions\n",
    "    - estimating posterior probabilities\n",
    "    - sum-of-squares for classification\n",
    "    - cross-entropy for two classes\n",
    "    - multiple independent attributes\n",
    "    - cross-entropy for multiple classes\n",
    "    - entropy\n",
    "    - general conditions for outputs to be probabilities\n",
    "7. Parameter Optimization Algorithms\n",
    "    - error surfaces\n",
    "    - local quadratic approximation\n",
    "    - linear output units\n",
    "    - optimization in practice\n",
    "    - gradient descent\n",
    "    - line search\n",
    "    - conjugate gradients\n",
    "    - scaled conjugate gradients\n",
    "    - newton's method\n",
    "    - quasi-newton methods\n",
    "    - the levenberg-marquardt algorithm\n",
    "8. Pre-processing and Feature extraction\n",
    "    - pre-processing and post-processing\n",
    "    - input normalization and encoding\n",
    "    - missing data\n",
    "    - time series prediction\n",
    "    - feature selection\n",
    "    - principal component analysis\n",
    "    - invariances and prior knowledge\n",
    "9. Learning and Generalization\n",
    "    - bias and variance\n",
    "    - regularization\n",
    "    - training with noise\n",
    "    - soft weight sharing\n",
    "    - growing and pruning algorithms\n",
    "    - committee of networks\n",
    "    - mixtures of experts\n",
    "    - model order selection\n",
    "    - Vapnik-Chervonekis dimension\n",
    "10. Bayesian Techniques\n",
    "    - bayesian learning of network weights\n",
    "    - distribution of network outputs\n",
    "    - applicaation to classification problems\n",
    "    - the evidence framework for $\\alpha$ and $\\beta$\n",
    "    - integration over hyperparamters\n",
    "    - Bayesian model comparison\n",
    "    - committees of networks\n",
    "    - Practical implementation of Bayesian techniques\n",
    "    - Monte Carlo methods\n",
    "    - Minimum discription length\n",
    "11. Symmetric Matrices\n",
    "12. Gaussian Integrals\n",
    "13. Lagrance Multipliers\n",
    "14. Calculus of Variations\n",
    "15. Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Recognition and Machine Learning\n",
    "1. Introduction\n",
    "    - Example: Polynomial curve fitting\n",
    "    - Probability theory\n",
    "        - probabilities densities\n",
    "        - expectations and covariances\n",
    "        - bayesian probabilities\n",
    "        - the Gaussia distribution\n",
    "        - Curve fitting re-visited\n",
    "        - Bayesian curve fitting\n",
    "     - Model selection\n",
    "     - The Curse of Dimensionality\n",
    "     - Decision Theory\n",
    "         - minimizing the misclassification rate\n",
    "         - minimizing the expected loss\n",
    "         - the reject option\n",
    "         - inference and decision\n",
    "         - loss functions for regression\n",
    "     - Information theory\n",
    "         - relative entropy and mutual information\n",
    "2. Probability distributions\n",
    "    - Binary variables\n",
    "        - the beta distribution\n",
    "    - Multinomial variables\n",
    "        - the Dirichlet distribution\n",
    "    - The Gaussian distribution\n",
    "        - Conditional Gaussian distributions\n",
    "        - Marginal Gaussian distributions\n",
    "        - Bayes' theorem for Gaussian variables\n",
    "        - Maximum likelihood for the Gaussian\n",
    "        - Sequential estimation\n",
    "        - Bayesian inference for the Gaussian\n",
    "        - Student's t-distribution\n",
    "        - Periodic variables\n",
    "        - Mixtures of Gaussians\n",
    "     - The Exponential family\n",
    "         - maximum likelihood and sufficient statistics\n",
    "         - conjugate priors\n",
    "         - noninformative priors\n",
    "     - Nonparametric Methods\n",
    "         - Kernel density estimatory\n",
    "         - Nearest-neighbor methods\n",
    "3. Linear Models for regression\n",
    "    - Linear Basis Function Models\n",
    "        - maximum likelihood and least squares\n",
    "        - geometry of least squares\n",
    "        - sequential learning\n",
    "        - regularized least squares\n",
    "        - multiple outputs\n",
    "    - The Bias-Variance Decomposition\n",
    "    - Bayesian Linear Regression\n",
    "        - parameter distribution\n",
    "        - predictive distribution\n",
    "        - equivalent kernel\n",
    "    - Bayesian Model Comparison\n",
    "    - The Evidence Approximation\n",
    "        - evaluation of the evidence function\n",
    "        - maximizing the evidence function\n",
    "        - effective number of parameters\n",
    "    - Limittions of Fixed Basis Functions\n",
    "4. Linear models for classification\n",
    "    - Discriminant Functions\n",
    "        - two classes \n",
    "        - multiple classes\n",
    "        - least squares for classification\n",
    "        - fisher's linear discriminant\n",
    "        - relation to least squares\n",
    "        - Fisher's discriminant for multiple classes\n",
    "        - the perceptron algorithm\n",
    "    - Probabilistic Generative Models\n",
    "        - continuous inputs\n",
    "        - maximum likelihood solution\n",
    "        - discrete features\n",
    "        - exponential family\n",
    "    - Probabilistic discriminative models\n",
    "        - fixed basis functions\n",
    "        - logistic regression\n",
    "        - iterative reweighted least squares\n",
    "        - multiclass logistic regression\n",
    "        - canonical link functions\n",
    "    - The Laplace Approximation\n",
    "        - model comparison and BIC\n",
    "    - Bayesian Logistic Regression\n",
    "        - Laplace approximation\n",
    "        - predictive distribution\n",
    "5. Neural networks\n",
    "    - Feed-forward network functions\n",
    "        - weight-space symmetries\n",
    "    - Network training\n",
    "        - parameter optimization\n",
    "        - local quadratic approximation\n",
    "        - use of gradient information\n",
    "        - gradient descent optimization\n",
    "    - Error backpropagation\n",
    "        - evaluation of error-function derivatives\n",
    "        - a simple example\n",
    "        - efficiency of backpropagation\n",
    "        - the jacobian matrix\n",
    "    - the hessian matrix\n",
    "        - diagonal approximation\n",
    "        - out product approximation\n",
    "        - inverse hessian\n",
    "        - finite differences\n",
    "        - exact evaluation of the Hessian\n",
    "        - Fast multiplication by the Hessian\n",
    "    - Regularization in Neural Networks\n",
    "        - consistent Gaussian priors\n",
    "        - Early stopping\n",
    "        - invariances\n",
    "        - tangent propagation\n",
    "        - training with transformed data\n",
    "        - convolutional networks\n",
    "        - soft weight sharing\n",
    "    - Mixture density networks\n",
    "    - Bayesian Neural networks\n",
    "        - posterior parameter distribution\n",
    "        - hyperparameter optimization\n",
    "        - Bayesian neural network for classification\n",
    "6. Kernel methods\n",
    "    - Dual representations\n",
    "    - Constructing kernels\n",
    "    - Radial Basis function networks\n",
    "        - Nadaraya-Watson model\n",
    "    - Gaussian Processes\n",
    "        - linear regression revisited\n",
    "        - Gaussian processes for regression\n",
    "        - learning the hyperparameters\n",
    "        - automatic relevance determination\n",
    "        - Gaussian processes for classification\n",
    "        - Laplace approximation\n",
    "        - Connection to neural networks\n",
    "7. Sparse Kernel Machines\n",
    "    - Maximum margin classifiers\n",
    "        - overlapping class distributions\n",
    "        - relation to logistic regression\n",
    "        - multiclass SVMs\n",
    "        - computational learning theory\n",
    "    - relevance vector machines\n",
    "        - RVM for regression\n",
    "        - analysis of sparsity\n",
    "        - RVM for classification\n",
    "8. Graphical models\n",
    "    - Bayesian networks\n",
    "        - example: polynomial regression\n",
    "        - generative models\n",
    "        - discrete variables\n",
    "        - linear-Gaussian models\n",
    "    - conditional independence\n",
    "        - three example graphs\n",
    "        - D-separation\n",
    "    - Markov random fields\n",
    "        - Conditional independence properties\n",
    "        - factoriation properties\n",
    "        - Illustration: image de-noising\n",
    "        - relation to directed graphs\n",
    "    - inference in graphical models\n",
    "        - inference on a chain\n",
    "        - trees\n",
    "        - factor graphs\n",
    "        - the sum-product algorithm\n",
    "        - the max-sum algorithm\n",
    "        - exact inference in general graphs\n",
    "        - loopy belief propagation\n",
    "        - learning the graph structure\n",
    "9. Mixture models and EM\n",
    "    - *K*-means clustering\n",
    "        - image segmentation and compression\n",
    "    - mixture of Gaussians\n",
    "        - maximum likelihood\n",
    "        - EM for gaussian mixtures\n",
    "    - and alternative view of EM\n",
    "        - Gaussian mixtures revisited\n",
    "        - relation to *K*-means\n",
    "        - mixtures of Bernoulli distributions\n",
    "        - EM for Bayesian linear regression\n",
    "    - The EM algorithm in general\n",
    "10. Approximate Inference\n",
    "    - Variational inference\n",
    "        - factorized distributions\n",
    "        - properties of factorized approximations\n",
    "        - example: the univariate Gaussian\n",
    "        - model comparison\n",
    "    - illustration: variational mixture of Gaussians\n",
    "        - variational distribution\n",
    "        - variational lower bound\n",
    "        - predictive density\n",
    "        - determining the number of components\n",
    "        - induced factorization\n",
    "    - variational linear regression\n",
    "        - variational distribution\n",
    "        - predictive distribution\n",
    "        - lower bound\n",
    "    - exponential family distributions\n",
    "        - variational message passing\n",
    "    - local variational methods\n",
    "    - variational logistic regression\n",
    "        - variational posterior distribution\n",
    "        - optimizing the variational parameters\n",
    "        - inference of hyperparameters\n",
    "    - excitation propagation\n",
    "        - example: the clutter problem\n",
    "        - expectation propagation on graphs\n",
    "11. Sampling Methods\n",
    "    - Basic Sampling Algorithms\n",
    "        - standard distributions\n",
    "        - rejection sampling\n",
    "        - adaptive rejection sampling\n",
    "        - importance sampling\n",
    "        - sampling-importance-resampling\n",
    "        - sampling and the EM algorithm\n",
    "    - Markov Chain Monte Carlo\n",
    "        - markov chain\n",
    "        - the matropolis-hastings algorithm\n",
    "    - Gibbs Sampling\n",
    "    - Slice sampling\n",
    "    - the hybrid monte carlo algorithm\n",
    "        - dynamical systems\n",
    "        - hybrid monte carlo\n",
    "    - estimating the partition function\n",
    "12. Continuous Latent Variables\n",
    "    - principal component analysis\n",
    "        - maximum variance formulation\n",
    "        - minimum-error formulation\n",
    "        - applications of PCA\n",
    "        - PCA for high-dimensional data\n",
    "    - probabilistic PCA\n",
    "        - maximum likelihood PCA\n",
    "        - EM algorithm for PCA\n",
    "        - Bayesian PCA\n",
    "        - Factor analysis\n",
    "    - Kernel PCA\n",
    "    - nonlinear latent variable models\n",
    "        - independent component analysis\n",
    "        - autoassociative neural networks\n",
    "13. Sequential Data\n",
    "    - markov models\n",
    "    - hidden markov models\n",
    "        - maximum likelihood for the HMM\n",
    "        - the forward-backward algorithm\n",
    "        - the sum-product algorithm for the HMM\n",
    "        - scaling factors\n",
    "        - the Viterbi algorithm\n",
    "        - extensions of the hidden Markov model\n",
    "    - linear dynamical systems\n",
    "        - inference in LDS\n",
    "        - learning in LDS\n",
    "        - extensions LDS\n",
    "        - particle filters\n",
    "14. Combining Models\n",
    "    - Bayesian Model averaging\n",
    "    - committees\n",
    "    - boosting\n",
    "        - minimizing exponential error\n",
    "        - error functions for boosting\n",
    "    - tree-based models\n",
    "    - conditional mixture models\n",
    "        - mixtures of linear regression models\n",
    "        - mixtures of logistic models\n",
    "        - mixtures of experts\n",
    "15. Data Sets\n",
    "16. Probability Distributions\n",
    "17. Properties of Matrices\n",
    "18. Calculus of Variations\n",
    "19. Lagrange Multipliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Learning OpenCV\n",
    "1. Overview\n",
    "2. Introduction to OpenCV\n",
    "    - first program - display a picture\n",
    "    - second program - avi video\n",
    "    - moving around\n",
    "    - a simple transformation\n",
    "    - a not-so-simple transformation\n",
    "    - input from a camera\n",
    "    - writing to an avi file\n",
    "3. Getting to Know OpenCV\n",
    "    - OpenCV primitive data types\n",
    "    - CvMat Matrix Structure\n",
    "    - IplImage Data Structure\n",
    "    - Matrix and Image operators\n",
    "    - drawing things\n",
    "    - data persistence\n",
    "    - integrated performance primitives\n",
    "4. HighGUI\n",
    "    - a portable graphics toolkit\n",
    "    - creating a window\n",
    "    - loading an image\n",
    "    - displaying images\n",
    "    - working with video\n",
    "    - ConvertImage\n",
    "5. Image Processing\n",
    "    - Smoothing\n",
    "    - Image Morphology\n",
    "    - Flood Fill\n",
    "    - Resize\n",
    "    - Image Pyramids\n",
    "    - Threshold\n",
    "6. Image Transforms\n",
    "    - convolution\n",
    "    - gradients and sobel derivatives\n",
    "    - laplace\n",
    "    - canny\n",
    "    - hough transforms\n",
    "    - remap\n",
    "    - stretch, shrink, warp, and rotate\n",
    "    - CartToPolar and PolarToCart\n",
    "    - LogPolar\n",
    "    - Discrete Fourier Transform (DFT)\n",
    "    - Discrete Cosine Transform (DCT)\n",
    "    - Integral Images\n",
    "    - Distance transform\n",
    "    - histogram equalization\n",
    "7. Histograms and Matching\n",
    "    - basic histogram data structure\n",
    "    - accessing histograms\n",
    "    - basic manipulations with histograms\n",
    "8. Contours\n",
    "    - memory storage\n",
    "    - sequences\n",
    "    - contour finding\n",
    "    - matching contours\n",
    "9. Image Parts and Segmentation\n",
    "    - parts and segments\n",
    "    - background subtraction\n",
    "    - watershed algorithm\n",
    "    - image repair by inpainting\n",
    "    - mean-shift segmentation\n",
    "    - delaunary triangularion, voronoi tesselation\n",
    "10. Tracking and Motion\n",
    "    - the basics of tracking\n",
    "    - corner finding\n",
    "    - subpixel corners\n",
    "    - invariant features\n",
    "    - optical flow\n",
    "    - mean-shift and camshift tracking\n",
    "    - motion templates\n",
    "    - estimators\n",
    "    - the condensation algorithm\n",
    "11. Camera Models and Calibration\n",
    "    - camera model\n",
    "    - calibration\n",
    "    - undistortion\n",
    "    - putting calibration all together\n",
    "    - rodrigues transform\n",
    "12. Projection and 3D Vision\n",
    "    - projections\n",
    "    - affine and perspective transformations\n",
    "    - POSIT: 3D pose estimation\n",
    "    - stereo imaging\n",
    "    - structure from motion\n",
    "    - fitting lines in two and three dimensions\n",
    "13. Machine Learning\n",
    "    - common routines in the ML library\n",
    "    - mehalanobis distance\n",
    "    - K-means\n",
    "    - Naive/Normal Bayes classifier\n",
    "    - binary decision trees\n",
    "    - boosting\n",
    "    - random trees\n",
    "    - face detection or Haar classifier\n",
    "14. OpenCV's Future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing and Computational Video\n",
    "1. Toward Plenoptic *Raumzeit* reconstruction\n",
    "2. two algorithms for motion estimation from alternate exposure images\n",
    "3. understanding what we cannot see: automatic analysis of 4D digital in-line holographic microscopy\n",
    "4. 3D reconstruction and video-based rendering of casually captured videos\n",
    "5. silhouette-based variational methods for single view reconstruction\n",
    "6. single image blind deconvolution with higher-order texture statistics\n",
    "7. compressive rendering of multidimensional scenes\n",
    "8. efficient rendering of light field images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Computer and Machine Vision: Theory, Algorithms, Practicalities\n",
    "1. Vision, the Challenge\n",
    "    - the man and his senses\n",
    "    - the nature of vision\n",
    "        - the process of recognition\n",
    "        - tackling the recognition problem\n",
    "        - object location\n",
    "        - scene analysis\n",
    "        - vision as inverse graphics\n",
    "    - from automated visual inspection to surveillance\n",
    "- ** I. Low-level vision**\n",
    "    1. Images and Imaging Operations\n",
    "        - gray scale versus color\n",
    "        - image processing operations\n",
    "            - some basic operations on grayscale images\n",
    "            - basic operations on binary images\n",
    "        - convolutions and point spread functions\n",
    "        - sequential versus parallel operations\n",
    "    2. Basic Image Filtering Operations\n",
    "        - noise suppression by gaussian smoothing\n",
    "        - median filters\n",
    "        - mode filters\n",
    "        - rank order filters\n",
    "        - reducing computational load\n",
    "        - sharp-unsharp masking\n",
    "        - shifts introducted by median filters\n",
    "            - continuum model of median shifts\n",
    "            - generalization to greyscale images\n",
    "            - problems with statistics\n",
    "        - discrete model of median shifts\n",
    "        - shift introduced by mode filters\n",
    "        - shifts introduces by mean and gaussian filters\n",
    "        - shifts introduced by rank order filters\n",
    "            - shifts in rectangular neighborhoods\n",
    "        - the role of filters in industrial applications of vision\n",
    "        - color in image filtering\n",
    "    3. Thresholding techniques\n",
    "        - region-growing methods\n",
    "        - thresholds\n",
    "            - finding a suitable threshold\n",
    "            - tackling the problem of bias in threshold selection\n",
    "        - adaptive thresholding \n",
    "            - the chow and kaneko approach\n",
    "            - local thresholding methods\n",
    "        - more thoroughgoing approaches to threshold selection\n",
    "            - variance-based thresholding\n",
    "            - entropy-based thresholding \n",
    "            - maximum likelihood thresholding\n",
    "        - the global valley approach to thresholding\n",
    "        - practical results obtained using the global valley method\n",
    "        - histogram concavity analysis\n",
    "    4. Edge detection\n",
    "        - basic theory of edge detection\n",
    "        - the template matching approach\n",
    "        - theory of 3 x 3 template operators\n",
    "        - the design of differential gradient operators\n",
    "        - the concept of a circular operator\n",
    "        - detailed implementation of circular operators\n",
    "        - the systematic design of differential edge operators\n",
    "        - hysteresis thresholding\n",
    "        - the canny operator\n",
    "        - the laplacian operator\n",
    "        - active contours\n",
    "    5. Corner and interest point detection\n",
    "        - template matching\n",
    "        - second-order derivative schemes\n",
    "        - a median filter-based corner detector\n",
    "        - the harris interest point operator\n",
    "        - corner orientation\n",
    "        - local invariant feature detectors and descriptors\n",
    "    6. Mathematical morphology\n",
    "        - dilation and erosion in binary images\n",
    "        - mathematical morphology\n",
    "        - grayscale processing\n",
    "        - effect of noise on morphological grouping operations\n",
    "    7. Texture\n",
    "        - graylevel co-occurrence matrices\n",
    "        - laws' texture energy approach\n",
    "        - Ade's eigenfilter approach\n",
    "        - appraisal of the laws and ade approaches\n",
    "- ** II. Intermediate-level vision**\n",
    "    1. Binary shape analysis\n",
    "        - connectedness in binary images\n",
    "        - object labeling and counting\n",
    "        - size filtering\n",
    "        - distance functions and their uses\n",
    "        - skeletons and thinning\n",
    "        - boundary tracking procedures\n",
    "    2. Boundary pattern analysis\n",
    "        - centroidal profiles\n",
    "        - tackling the problems of occlusion\n",
    "        - accuracy of boundary length measures\n",
    "    3. Line detection\n",
    "        - application of the Hough transform to line detection\n",
    "        - the Foot-of-Normal method \n",
    "        - longitudinal line localization\n",
    "        - final line fitting\n",
    "    4. circle and ellipse detection\n",
    "        - Hough-based schemes for circular object detection\n",
    "        - the problem of unknown circle radius\n",
    "        - the problem of accurate center location\n",
    "        - overcoming the speed problem\n",
    "        - ellipse detection\n",
    "        - human iris location\n",
    "        - hole detection\n",
    "    5. the Hough transform and its nature\n",
    "        - the generalized Hough transform\n",
    "        - spatial matched filtering in images\n",
    "        - from spatial matched filters to generalized hough transforms\n",
    "        - gradient weighting versus uniform weighting\n",
    "        - fast implementations of the Hough transform\n",
    "        - the approach of Gerig and Klein\n",
    "    6. pattern matching techniques\n",
    "        - a graph-theoretic approach to object location\n",
    "        - possibilities for saving computation\n",
    "        - using the generalized Hough transform for feature collation\n",
    "        - generalizing the maximal clique and other approaches\n",
    "- ** III. 3-D Vision and motion**\n",
    "    1. the Three-dimensional world\n",
    "        - 3D vision - the variety of methods\n",
    "        - projection schemes for three-dimensional vision\n",
    "            - binocular images\n",
    "            - the correspondence problem\n",
    "        - shape from shading\n",
    "        - photometric stereo\n",
    "        - the assumption of surface smoothness\n",
    "        - shape from texture\n",
    "        - use of structured lighting\n",
    "        - three-dimensional object recogntion schemes\n",
    "        - Horaud's Junction orientation technique\n",
    "        - and important paradigm - location of industrial parts\n",
    "    2. tackling the perspective n-point problem\n",
    "        - the phenomenon of perspective inversion\n",
    "        - ambiguity of pose under weak perspective projection\n",
    "        - obtaining unique solutions to the pose problem\n",
    "    3. Invariants and perspective\n",
    "        - cross-ratios: the \"ratio of ratios\" concept\n",
    "        - invariants for noncollinear points\n",
    "        - invariants for points on conics\n",
    "        - differential and semi-differential invariants\n",
    "        - symmetric cross-ratio functions\n",
    "        - vanishing point detection\n",
    "        - apparent centers of circles and ellipsees\n",
    "        - the route to face recognition\n",
    "        - perspective effects in art and photography\n",
    "    4. image transformations and camera calibration\n",
    "        - image transformations\n",
    "        - camera calibration\n",
    "        - intrinsic and extrinsic parameters\n",
    "        - correcting for radial distortions\n",
    "        - multiple view vision\n",
    "        - generalized epipolar geometry\n",
    "        - the essential matrix\n",
    "        - the fundamental matrix\n",
    "        - an update on the eight-point algorithm\n",
    "        - image rectification\n",
    "        - 3D-reconstruction\n",
    "    5. motion\n",
    "        - optical flow\n",
    "        - interpretation of optical flow fields\n",
    "        - using focus of expansion to avoid collision\n",
    "        - time-to-adjacency analysis\n",
    "        - basic difficulties with the optical flow model\n",
    "        - stereo from motion\n",
    "        - the kalman filter\n",
    "        - wide baseline matching\n",
    "- ** IV. Toward Real-time pattern recognition systems**\n",
    "    1. automated visual inspection\n",
    "    2. inspection of cereal grains\n",
    "    3. surveillance\n",
    "    4. in-vehicle vision systems\n",
    "    5. statistical pattern recognition\n",
    "        - the nearest neighbor algorithm\n",
    "        - Bayes' decision theory\n",
    "            - the naive bayes' classifier\n",
    "        - relation of the nearest neighbor and Bayes' approaches\n",
    "        - the optimum number of features\n",
    "        - the optimum number of features\n",
    "        - cost functions and error-reject tradeoff\n",
    "        - the receiver operating characteristic\n",
    "        - multiple classifiers\n",
    "        - cluster analysis\n",
    "            - supervised and unsupervised learning\n",
    "            - clustering procedures\n",
    "        - principal components analysis\n",
    "        - the relevance of probability in image analysis\n",
    "        - the support vector machine\n",
    "        - artificial neural networks\n",
    "        - the back-propagation algorithm\n",
    "        - MLP architectures\n",
    "        - overfitting the training data\n",
    "    6. image acquisition\n",
    "        - illumination schemes\n",
    "        - cameras and digitization\n",
    "        - the sampling theorem\n",
    "        - hyperspectral imaging\n",
    "    7. real-time hardware and systems design considerations\n",
    "    8. Epilogue - Perspectives in vision\n",
    "        - parameters of importance in machine vision\n",
    "        - tradeoffs\n",
    "        - moore's law in action\n",
    "        - hardware, algorithms and processes\n",
    "        - the importance of choice in representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biologically motivated computer vision\n",
    "1. CBF: a new framework for object categorization in cortex\n",
    "2. the perception of spatial layout in a virtual world\n",
    "- ** segmentation, detection and object recogntion**\n",
    "1. towards a computational model for object recognition in IT cortex\n",
    "2. straight line detection as an optimization problem: an approach motivated by the jumping spider visual system\n",
    "3. factorial code representation of faces for recognition\n",
    "4. distinctive features should be learned\n",
    "5. moving object segmentation based on human visual sensitivity\n",
    "6. object classification using a fragment-based representation\n",
    "- **computational model**\n",
    "1. confrontation of retinal adaptation model with key features of psychophysical gain behavior dynamics\n",
    "2. polarization-based orientation in a nautral environment\n",
    "2. computational model of eye movements in reading using foveated vision\n",
    "3. new eyes for shape and motion estmation\n",
    "4. top-down attentional control at feature space for robust pattern recognition\n",
    "5. a model for visual camoufalge breaking\n",
    "- ** active and attentive vision**\n",
    "1. *development of a biologically inspired real-time visual attention system *\n",
    "2. real-time visual tracking insensitive to three-dimensional rotation of objects\n",
    "3. heading perception and moving objects\n",
    "4. dynamic vergence using disparity flux\n",
    "5. computing in cortical columns: curve inference and stereo correspondence\n",
    "6. active vision from multiple cues\n",
    "7. an efficient data structure for feature extraction in a foveated environment\n",
    "8. parallel trellis based stereo matching using constraints\n",
    "9. unsupervised learning of biologically plausible object recognition strategies\n",
    "10. structured kalman filter for tracking partially occluded moving objects\n",
    "11. face recognition under varying views\n",
    "12. time delay effects on dynamic patterns in a coupled neural model\n",
    "13. pose-independent object representation by 2D views\n",
    "14. an image enhancement technique based on wavelets\n",
    "15. front-end vision: a multiscale geometry engine\n",
    "16. face reconstruction using a small set of feature points\n",
    "17. modeling character superiority effect in korean characters by using IAM\n",
    "18. wavelet-based stereo vision\n",
    "19. a neural network model for long-range contour diffusion by visual cortex\n",
    "20. automatic generation of photo-realisitic mosaic image\n",
    "21. the effect of color differences on the detection of the target in visual search\n",
    "22. a color-triangle-based approach to the detection of the human face\n",
    "23. multiple people tracking using an appearance model based on temporal color\n",
    "24. *biology-inspired early vision system for a spike processing neurocomputer*\n",
    "25. a biologically-motivated approach to image representation and its application to neuromorphology\n",
    "26. a fast circular edge detector for the iris region segmentation\n",
    "27. face recognition using foveal vision\n",
    "28. fast distance computation with a stereo head-eye system\n",
    "29. bio-inspired texture segmentation architectures\n",
    "30. scene segmentation by chaotic synchronization and desynchronization\n",
    "31. electronic circuit model of color sensitive retinal cell network\n",
    "32. **the role of natural image statistics in biological motion estimation**\n",
    "33. a humanoid vision system for versatile interaction\n",
    "- **ICA and space-variant learning**\n",
    "    1. the spectral independent components of natural scenes\n",
    "    2. **topographic ICA as a model of natural image statistics**\n",
    "    3. orientation of contrast detection in space-variant images\n",
    "    4. multiple object tracking in multiresolution image sequences\n",
    "    5. a geometric model for cortical magnification\n",
    "- **Neural Networks and Applications**\n",
    "    1. tangent fields from population coding\n",
    "    2. efficient search technique for hand gesture tracking in three dimensions\n",
    "    3. robust, real-time motion estimation from long image sequences using kalman filtering\n",
    "    4. active and adaptive vision: neural network models\n",
    "    5. temporal structure in the input to vision can promote spatial grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Feature Extraction\n",
    "1. Introduction\n",
    "    - human and computer vision\n",
    "    - the human vision system\n",
    "        - the eye\n",
    "        - the neural system\n",
    "        - processing\n",
    "    - computer vision systems\n",
    "        - cameras\n",
    "        - computer interfaces\n",
    "        - processing an image\n",
    "    - mathematical systems\n",
    "    - associated literature\n",
    "2. Images, sampling, and frequency domain processing\n",
    "    - image formation\n",
    "    - the Fourier transform\n",
    "    - the sampling criterion\n",
    "    - the discrete Fourier transform\n",
    "    - Other properties of the Fourier transform\n",
    "        - shift invariance\n",
    "        - rotation\n",
    "        - frequency scaling\n",
    "        - superposition (linearly)\n",
    "    - transformations other than Fourier\n",
    "        - discrete cosine transform\n",
    "        - discrete Hartley transform\n",
    "        - introductory wavelets\n",
    "3. Basic image processing operations\n",
    "    - histograms\n",
    "    - point operators\n",
    "        - basic point operations\n",
    "        - histogram normalization\n",
    "        - histogram equalization\n",
    "        - thresholding\n",
    "    - group operations\n",
    "        - template convolution\n",
    "        - averaging operator\n",
    "        - gaussian averaging operator\n",
    "    - other statistical operators\n",
    "        - median filter\n",
    "        - mode filter\n",
    "        - anisotropic diffusion\n",
    "        - force field transform\n",
    "    - mathematical morphology\n",
    "        - morphological operators\n",
    "        - gray-level morphology\n",
    "        - gray-leel erosion and dilation\n",
    "        - minkowski operators\n",
    "4. Low-level feature extraction (including edge detection)\n",
    "    - edge detection\n",
    "        - first-order operators\n",
    "        - second-order operators\n",
    "    - phase congruency\n",
    "    - localized feature extraction\n",
    "        - detecting image curvature (corner extraction)\n",
    "    - describing image motion\n",
    "5. High-level feature extraction: fixed shape matching\n",
    "    - thresholding and subtraction\n",
    "    - template matching\n",
    "    - feature etraction by low-level features\n",
    "    - Hough transform\n",
    "6. High-level feature extraction: deformable shape analysis\n",
    "    - deformable shape analysis\n",
    "    - active contours (snakes)\n",
    "    - shape skeletonization\n",
    "    - flexible shape models-active shape and active appearance\n",
    "7. Object description\n",
    "    - boundary descriptions\n",
    "    - region descriptors\n",
    "8. Introduction to texture description, segmentation, and classification\n",
    "    - texture description\n",
    "    - classification\n",
    "    - segmentation\n",
    "9. Moving Object detection and description\n",
    "    - moving object detection\n",
    "    - tracking moving features\n",
    "    - moving feature extraction and description\n",
    "10. A1: Camera Geometry fundamentals\n",
    "    - perspective camera model\n",
    "    - affine camera\n",
    "    - weak perspective model\n",
    "11. A2: Least squares analysis\n",
    "    - the least squares criterion\n",
    "    - curve fitting by least squares\n",
    "12. A3: Principal components analysis\n",
    "    - data\n",
    "    - covariance\n",
    "    - covariance matrix\n",
    "    - data transformation\n",
    "    - inverse transformation\n",
    "    - eigenproblem\n",
    "13. A4: color images\n",
    "    - tristimulus theory\n",
    "    - the colorimetric equation\n",
    "    - luminosity function\n",
    "    - perception based color models: the CIE RBB and CIE XYZ\n",
    "    - uniform color spaces: CIE LUV and CIE LAB\n",
    "    - additive and subtractive color models: RGB and CMY\n",
    "    - luminance and chrominance color models: YUV, YIQ, and YCbCr\n",
    "    - perceptual color models: HSV and HLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fundamentals of Computer Vision\n",
    "1. Imaging geometry\n",
    "    - translation and scaling\n",
    "    - rotation\n",
    "    - perspective transform\n",
    "    - camera model\n",
    "    - camera calibration\n",
    "    - recovering camera parameters\n",
    "    - Rodrigue's Formula\n",
    "    - pose estimation\n",
    "2. Edge Detection\n",
    "    - types of edge\n",
    "    - three stages in edge detection\n",
    "    - filtering stage\n",
    "    - differentiation state\n",
    "    - detection state\n",
    "        - normalized gradient magnitude\n",
    "        - non-maxima suppression\n",
    "    - classes of edge detection schemes\n",
    "    - gradient operators\n",
    "    - facet model\n",
    "    - laplacian of gaussian opertor\n",
    "    - properties of Gaussian \n",
    "        - scaling\n",
    "        - separability\n",
    "        - symmetry\n",
    "    - Canny's edge detector\n",
    "    - scale space\n",
    "3. Region Segmentation\n",
    "    - simple segmentation\n",
    "        - thresholds and histograms\n",
    "        - peakiness test\n",
    "    - connected component algorithms\n",
    "    - seed segmentation\n",
    "    - region growing\n",
    "    - region adjacency graph\n",
    "    - geometrical properties of regions\n",
    "4. 2-D Shape\n",
    "    - Hough transform\n",
    "    - shape number\n",
    "    - pyramids\n",
    "    - quad trees\n",
    "    - medial axis transform\n",
    "    - Moravec's interest operator\n",
    "5. Motion\n",
    "    - optical flow\n",
    "    - token based optical flow\n",
    "    - motion correspondence using multiple frames\n",
    "    - structure from motion\n",
    "6. Stereo and Shape From Shading\n",
    "    - stereo\n",
    "        - stereo geometry\n",
    "        - steps in token based stereo\n",
    "        - marr-poggio algorithm\n",
    "        - correlation based stereo methods\n",
    "        - barnard's stereo algorithm\n",
    "    - shape from shading\n",
    "    - photometric stereo\n",
    "7. Range Images\n",
    "    - range image formation\n",
    "    - surface characteristics\n",
    "    - edges in range images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing, Analysis and Machine Vision\n",
    "1. Introduction\n",
    "2. The image, its representations and properties\n",
    "    - image digitization\n",
    "        - sampling\n",
    "        - quantization\n",
    "    - digital image properties\n",
    "        - metric and topological properties of digital images\n",
    "        - histograms\n",
    "        - entropy\n",
    "        - visual perception of the image\n",
    "        - image quality\n",
    "        - noise in images\n",
    "    - Color images\n",
    "        - physics of color\n",
    "        - color perceived by humans\n",
    "        - color spaces\n",
    "        - palette images\n",
    "        - color constancy\n",
    "    - Cameras: an overview\n",
    "        - photosensitive sensors\n",
    "        - a monochromatic camera\n",
    "        - a color camera\n",
    "3. The image, its mathematical and physical background\n",
    "    - Overview\n",
    "        - linearity\n",
    "        - the dirac distribution and convolution\n",
    "    - Linear integral transforms\n",
    "        - images as linear systems\n",
    "        - introduction to linear integral transforms\n",
    "        - 1D Fourier transform\n",
    "        - 2D Fourier transform\n",
    "        - sampling and the shannong constraint\n",
    "        - Discrete cosine transform\n",
    "        - Wavelet transform\n",
    "        - Eigen-analysis\n",
    "        - singular value decomposition\n",
    "        - principal component analysis\n",
    "        - other orthogonal image transforms\n",
    "    - Images as stochastic processes\n",
    "    - image formation physics\n",
    "        - images as radiometric measurements\n",
    "        - image capture and geometric optics\n",
    "        - lens abberations and radial distortion\n",
    "        - image capture from a radiometric point of view\n",
    "        - surface reflectance\n",
    "4. Data structure for image analysis\n",
    "    - levels of image data representation\n",
    "    - traditional image data structures\n",
    "        - matrices\n",
    "        - chains\n",
    "        - topological data structure\n",
    "        - relational structure\n",
    "    - hierarchical data structures\n",
    "        - pyramids\n",
    "        - quadtrees\n",
    "5. Image pre-processing\n",
    "    - pixel brightness transformations\n",
    "        - position-dependent brightness correction\n",
    "        - gray-scale transformation\n",
    "    - geometric transformations\n",
    "        - pixel co-ordinate transformation\n",
    "        - brightness interpolation\n",
    "    - local pre-processing\n",
    "        - image smoothing\n",
    "        - edge detectors\n",
    "        - zero-crossings of the second derivative\n",
    "        - scale in image processing\n",
    "        - Canny edge detection\n",
    "        - parametric edge models\n",
    "        - edges in multi-spectral images\n",
    "        - local pre-processing in the frequency domain\n",
    "        - line detection by local pre-processing operators\n",
    "        - detection of corners (interest points)\n",
    "        - detection of maximally stable extremal regions\n",
    "     - Image restoration\n",
    "6. Segmentation I\n",
    "    - Thresholding\n",
    "    - edge-based segmentation\n",
    "    - region-based segmentation\n",
    "    - matching\n",
    "    - evaluation issues in segmentation\n",
    "7. Segmentation II\n",
    "    - mean shift segmentation\n",
    "    - active contour models - snakes\n",
    "    - geometric deformable models - level sets and geodesic active contours\n",
    "    - fuzzy connectivity\n",
    "    - towards 3D graph-based image segmentation\n",
    "    - graph cut segmentation\n",
    "    - optical single and multiple surface segmentation\n",
    "8. Shape representation and description\n",
    "    - region identification\n",
    "    - contour-based shape representation and description\n",
    "    - region-based shape repreesntation and description\n",
    "    - shape classes\n",
    "9. Object recognition\n",
    "    - knowledge representation\n",
    "    - statistical pattern recognition\n",
    "        - classifier principles\n",
    "        - classifier setting\n",
    "        - classifier learning\n",
    "        - support vector machines\n",
    "        - cluster analysis\n",
    "    - neural nets\n",
    "        - feed-forward networks\n",
    "        - unsupervised learning\n",
    "        - hopfield neural nets\n",
    "    - syntactic pattern recognition\n",
    "    - recognition as graph matching\n",
    "        - isomorphism of graphs and sub-graphs\n",
    "        - similarity of graphs\n",
    "    - optimization techniques in recognition\n",
    "        - genetic algorithms\n",
    "        - simulated annealing\n",
    "    - fuzzy systems\n",
    "    - boosting in pattern recognition\n",
    "10. Image understanding\n",
    "    - image understanding control strategies\n",
    "    - RANSAC: fitting via random sample consensus\n",
    "    - point distribution models\n",
    "    - active appearance models\n",
    "    - pattern recognition methods in image understanding\n",
    "    - boosted cascade of classifiers for rapid object detection\n",
    "    - scene labeling and constraint propagation\n",
    "    - semantic image segmentation and understanding\n",
    "    - hidden Markov models\n",
    "    - Gaussian mixture models and expectation-maximization\n",
    "11. 3D vision, geometry\n",
    "    - 3D vision tasks\n",
    "    - basics of projective geometry\n",
    "        - points and hyperplanes in projective space\n",
    "        - homography\n",
    "        - estimating homography from point correspondences\n",
    "    - a single perspective camera\n",
    "    - scene reconstruction from multiple views\n",
    "    - two cameras, stereopsis\n",
    "        - epipolar geometry; fundamental matrix\n",
    "        - relative motion of the camera; essential matrix\n",
    "        - decomposing the fundamental matrix to camera matrices\n",
    "        - estimating the fundamental matrix from point correspondences\n",
    "        - rectified configuration of two cameras\n",
    "        - computing rectification\n",
    "    - three cameras and trifocal tensor\n",
    "    - 3D information from radiometric measurements\n",
    "12. Use of 3D vision\n",
    "    - Shape from X\n",
    "        - shape from motion\n",
    "        - shape from texture\n",
    "    - full 3D objects\n",
    "    - 3D model-based vision\n",
    "    - 2D view-based representations of a 3D scene\n",
    "    - 3D reconstruction from an unorganized set of 2D views \n",
    "13. Mathematical morphology\n",
    "    - binary dilation and erosion\n",
    "        - dilation\n",
    "        - erosion\n",
    "        - hit-or-miss transformation\n",
    "        - opening and closing\n",
    "    - gray-scale dilation and erosion\n",
    "    - skeletons and object marking\n",
    "    - granulometry\n",
    "    - morphological segmentation and watershed\n",
    "14. Image data compression\n",
    "    - image data properties\n",
    "    - discrete image transforms in image data compression\n",
    "    - predictive compression methods\n",
    "    - vector quantization\n",
    "    - hierarchical and progressive compression methods\n",
    "    - JPEG and MPEG\n",
    "15. Texture\n",
    "    - statistical texture description\n",
    "        - methods based on spatial frequencies\n",
    "        - co-occurence matrices\n",
    "        - edge frequency\n",
    "        - primitive length (run length)\n",
    "        - laws' texture energy measures\n",
    "        - fractal texture description\n",
    "        - multiscale texture description - wavelet domain approaches\n",
    "    - syntactic texture description methods\n",
    "    - hybrid texture discription methods\n",
    "    - tecture recognition method application\n",
    "16. Motion analysis\n",
    "    - differential motion analysis methods\n",
    "    - optical flow\n",
    "        - optical flow computation\n",
    "        - global and local optical flow estimation\n",
    "        - combines local-global optical flow estimation\n",
    "        - optical flow in motion analysis\n",
    "    - analysis based on correspondence of interest points\n",
    "    - detection of specific motion patterns\n",
    "    - video tracking\n",
    "        - background modeling\n",
    "        - kernel-based tracking\n",
    "        - object path analysis\n",
    "    - motion models to aid tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision - Algorithms and Applications\n",
    "1. Introduction\n",
    "2. Image formation\n",
    "    - geometric primitives and transformations\n",
    "    - photometric image formation\n",
    "    - the digital camera\n",
    "3. Image processing\n",
    "    - point operators\n",
    "    - linear filtering\n",
    "    - more neighborhood operators\n",
    "    - Fourier transforms\n",
    "    - pyramids and wavelets\n",
    "    - geometric transformations\n",
    "    - global optimization \n",
    "4. Feature detection and matching\n",
    "    - points and patches \n",
    "    - edges\n",
    "    - lines\n",
    "5. segmentation\n",
    "    - active contours\n",
    "    - split and merge\n",
    "    - mean shift and mode finding\n",
    "    - normalized cuts\n",
    "    - graph cuts and energy-based methods\n",
    "6. Feature-based alignment\n",
    "    - 2D and 3D feature-based alignment\n",
    "    - pose estimation\n",
    "    - geometric intrinsic calibration\n",
    "7. structure from motion\n",
    "    - triangulation\n",
    "    - two-frame structure from motion\n",
    "    - factorization\n",
    "    - bundle adjustment\n",
    "    - constrained structure from motion\n",
    "8. Dense motion estimation\n",
    "    - translational alignment\n",
    "    - parametric motion\n",
    "    - spline-based motion\n",
    "    - optical flow\n",
    "    - layered motion\n",
    "9. Image stitching\n",
    "    - motion models\n",
    "    - global alignment\n",
    "    - compositing\n",
    "10. computational photography\n",
    "    - photometric calibration\n",
    "    - high dynamic range imaging\n",
    "    - super-resolution and blur removal \n",
    "    - image matting and compositing\n",
    "    - texture analysis and synthesis\n",
    "11. stereo correspondence\n",
    "    - epipolar geometry\n",
    "    - sparse correspondence\n",
    "    - dense correspondence\n",
    "    - local methods\n",
    "    - global optimization\n",
    "    - multi-view stereo\n",
    "12. 3D reconstruction\n",
    "    - shape from X\n",
    "    - active rangefinding\n",
    "    - surface representations\n",
    "    - point-based representation\n",
    "    - volumetric representations\n",
    "    - model-based reconstruction\n",
    "    - recovering texture maps and albedos\n",
    "13. Image-based redering\n",
    "    - view interpolation\n",
    "    - layered depth images\n",
    "    - light fields and lumigraphs\n",
    "    - environment mattes\n",
    "    - video-based rendering\n",
    "14. Recognition\n",
    "    - object detection\n",
    "    - face recognition\n",
    "    - instance recognition\n",
    "    - category recognition\n",
    "    - context and scene understanding\n",
    "    - recognition database and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##(Shalizi) Probability, Statistics and Stochastic Processes\n",
    "- **I. Probability**\n",
    "    1. What's a Probability anyway?\n",
    "    2. Probability calculus\n",
    "        - basic rules\n",
    "        - conditional probabilities\n",
    "    3. Random variables\n",
    "        - properties of random variables\n",
    "            - functions of random variables\n",
    "            - multiple random variables; independence\n",
    "        - expectation\n",
    "            - expectation of multiple variables\n",
    "        - moments\n",
    "            - particularly important moments\n",
    "            - mean\n",
    "            - variance and standard deviation\n",
    "    4. Important Discrete Distributions\n",
    "        - the bernoulli distribution\n",
    "        - the binomial distribution\n",
    "        - the poisson distribution\n",
    "        - first moments of these distributions\n",
    "    5. Continuous Random Variables\n",
    "        - the cumulative distribution function\n",
    "        - the probability density function\n",
    "        - continuous expectations\n",
    "    6. Important Continuous Distributions\n",
    "        - the exponential distribution\n",
    "        - the normal or gaussian distribution\n",
    "        - the $\\chi^2$ distribution\n",
    "        - the lognormal distribution\n",
    "        - power-law distributions\n",
    "        - first moments and pdfs of these distributions\n",
    "    7. Tricks with Random Variables\n",
    "        - the law of large numbers\n",
    "        - the central limit theorem\n",
    "            - the extraordinary importance of the CLT\n",
    "            - ways in which the CLT can fail\n",
    "            - the many-independent-causes story for why things are gaussian\n",
    "            - multiplicative noise and the lognormal distribution\n",
    "- **II. Statistics**\n",
    "    1. The Care and Handling of data\n",
    "        - counting\n",
    "            - the question of bins\n",
    "            - histograms\n",
    "            - percentiles\n",
    "            - median\n",
    "            - mode\n",
    "        - adding\n",
    "            - sample mean\n",
    "            - sample variance\n",
    "        - correlating\n",
    "            - covariance\n",
    "            - the correlation coefficient\n",
    "    2. Sampling\n",
    "        - the notion of \"a statistic\"\n",
    "        - loss of variability under sampling\n",
    "        - figuring the sample distribution; Monte Carlo methods\n",
    "    3. Estimation\n",
    "        - point estimates\n",
    "            - bias, variance, and other sorts of quality\n",
    "            - some common kinds of estimates\n",
    "            - least squares\n",
    "            - maximum likelihood\n",
    "        - curve-fitting or regression\n",
    "        - propagation of error\n",
    "        - confidence regions\n",
    "    4. Hypothesis testing\n",
    "        - goodness-of-fit\n",
    "            - signficant lack of fit\n",
    "            - the $\\chi^2$ test\n",
    "        - the null hypothesis and its rivals\n",
    "            - the *status quo* null\n",
    "            - the it-would-be-the-worst-mistake null\n",
    "            - the random-effects null\n",
    "            - the alternative hypothesis\n",
    "        - formalism of tests\n",
    "            - the test statistics\n",
    "            - the regions\n",
    "            - the kinds of errors; error probabilities\n",
    "            - significance level or size\n",
    "            - power\n",
    "            - severity\n",
    "            - the trade-offs\n",
    "            - test for whether two sample means are equal\n",
    "    5. Funky statistics\n",
    "        - nonparametric estimation and fitting\n",
    "        - machine learning\n",
    "        - causal inference\n",
    "        - ecological inference\n",
    "        - optimal experimental design\n",
    "- **III. Stochastic Processes**\n",
    "    1. Sequences of Random variables\n",
    "        - representing stochastic processes with operators\n",
    "        - important properties of stochastic processes\n",
    "            - stationarity\n",
    "            - ergodicity\n",
    "            - mixing\n",
    "    2. Markov processes\n",
    "        - Markov chains and matrices\n",
    "        - some classifications of states, distributions and chains\n",
    "        - Higher-order Markov chains\n",
    "        - Hidden Markov models\n",
    "    3. examples of markov procesess\n",
    "        - Bernoulli trials\n",
    "        - biased drift on a ring\n",
    "        - the random walk\n",
    "    4. Continuous-Time stochastic processes\n",
    "        - the Poisson process\n",
    "        - brownian motion, or the wiener process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
